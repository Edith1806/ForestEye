const ort = require("onnxruntime-node");
const fs = require("fs");
const path = require("path");

(async () => {
  try {
    const modelPath = path.join(__dirname, "model", "best.onnx");
    console.log("ğŸ” Checking model at:", modelPath);

    if (!fs.existsSync(modelPath)) {
      console.error("âŒ Model file not found!");
      return;
    }

    const session = await ort.InferenceSession.create(modelPath);
    console.log("âœ… Model loaded successfully");

    console.log("\nğŸ§  Inputs:");
    for (const name of session.inputNames) {
      const meta = session.inputMetadata[name];
      console.log(`- Name: ${name}`);
      console.log(`  Meta:`, meta || "(no metadata)");
    }

    console.log("\nğŸ¯ Outputs:");
    for (const name of session.outputNames) {
      const meta = session.outputMetadata[name];
      console.log(`- Name: ${name}`);
      console.log(`  Meta:`, meta || "(no metadata)");
    }

  } catch (err) {
    console.error("âŒ Error loading model:", err);
  }
})();
